# and the most liked status is...
mymessages[which.max(mylikes)]
# go to 'https://developers.facebook.com/tools/explorer' to get your access token
access_token <- "AAACEdEose0cBALsYrcUOAarr0ZBPeYHmreIZC84wauIOvdZBdrM6ajZAI39Sxx2RLMc1D8pQqdYwaY4Up70RZBj2QnSdGD5ft7gmF7OM2GAZDZD"
require(RCurl)
require(rjson)
options(RCurlOptions = list(capath = system.file("CurlSSL", "cacert.pem", package = "RCurl"), ssl.verifypeer = FALSE))
# Facebook json function copied from original (Romain Francois) post
facebook <-  function( path = "me", access_token, options){
if( !missing(options) ){
options <- sprintf( "?%s", paste( names(options), "=", unlist(options), collapse = "&", sep = "" ) )
} else {
options <- ""
}
data <- getURL( sprintf( "https://graph.facebook.com/%s%s&access_token=%s", path, options, access_token ) )
fromJSON( data )
}
### MY FACEBOOK POSTS
myposts <- list()
i <- 0
next.path <- "me/posts"
# download all my posts
while(length(next.path)!=0) {
i<-i+1
myposts[[i]] <- facebook(path=next.path , access_token=access_token)
next.path <- sub("https://graph.facebook.com/", "", myposts[[i]]$paging$'next')
}
myposts[[i]] <- NULL
# parse the list, extract number of likes and the corresponding text (status)
parse.master <- function(x, f)
sapply(x$data, f)
parse.likes <- function(x) if(!is.null(x$likes$count)) x$likes$count else 0
mylikes <- unlist(sapply(myposts, parse.master, f=parse.likes))
parse.messages <- function(x) if(!is.null(x$message)) x$message else NA
mymessages <- unlist(sapply(myposts, parse.master, f=parse.messages))
# and the most liked status is...
mymessages[which.max(mylikes)]
# the code uses 'facebook' function from the previous gist (https://gist.github.com/1634662) or
# see the original http://romainfrancois.blog.free.fr/index.php?post/2012/01/15/Crawling-facebook-with-R
# scrape the list of friends
friends <- facebook( path="me/friends" , access_token=access_token)
# extract Facebook IDs
friends.id <- sapply(friends$data, function(x) x$id)
# extract names
friends.name <- sapply(friends$data, function(x)  iconv(x$name,"UTF-8","ASCII//TRANSLIT"))
# short names to initials
initials <- function(x) paste(substr(x,1,1), collapse="")
friends.initial <- sapply(strsplit(friends.name," "), initials)
# friendship relation matrix
N <- length(friends.id)
friendship.matrix <- matrix(0,N,N)
for (i in 1:N) {
tmp <- facebook( path=paste("me/mutualfriends", friends.id[i], sep="/") , access_token=access_token)
mutualfriends <- sapply(tmp$data, function(x) x$id)
friendship.matrix[i,friends.id %in% mutualfriends] <- 1
}
require(Rgraphviz)
# convert relation matrix to graph
g <- new("graphAM", adjMat=friendship.matrix)
# ellipse graph with initials
pdf(file="facebook1.pdf", width=25, height=25)
attrs <- list(node=list(shape="ellipse", fixedsize=FALSE))
nAttrs <- list(label=friends.initial)
names(nAttrs$label) <- nodes(g)
plot(g, "neato", attrs=attrs, nodeAttrs=nAttrs)
dev.off()
# go to 'https://developers.facebook.com/tools/explorer' to get your access token
access_token <- "AAACEdEose0cBAI3tAm30KPPQdapGLQ9Mx3nd15rgVUH3kt97uPWd5qpffR2ZCKaO2M4oQP3RkxgT48xZB9LFMhKbZAZA2r5HrHCLDZC8vhQZDZD"
require(RCurl)
require(rjson)
options(RCurlOptions = list(capath = system.file("CurlSSL", "cacert.pem", package = "RCurl"), ssl.verifypeer = FALSE))
# Facebook json function copied from original (Romain Francois) post
facebook <-  function( path = "me", access_token, options){
if( !missing(options) ){
options <- sprintf( "?%s", paste( names(options), "=", unlist(options), collapse = "&", sep = "" ) )
} else {
options <- ""
}
data <- getURL( sprintf( "https://graph.facebook.com/%s%s&access_token=%s", path, options, access_token ) )
fromJSON( data )
}
### MY FACEBOOK POSTS
myposts <- list()
i <- 0
next.path <- "me/posts"
# download all my posts
while(length(next.path)!=0) {
i<-i+1
myposts[[i]] <- facebook(path=next.path , access_token=access_token)
next.path <- sub("https://graph.facebook.com/", "", myposts[[i]]$paging$'next')
}
myposts[[i]] <- NULL
# parse the list, extract number of likes and the corresponding text (status)
parse.master <- function(x, f)
sapply(x$data, f)
parse.likes <- function(x) if(!is.null(x$likes$count)) x$likes$count else 0
mylikes <- unlist(sapply(myposts, parse.master, f=parse.likes))
parse.messages <- function(x) if(!is.null(x$message)) x$message else NA
mymessages <- unlist(sapply(myposts, parse.master, f=parse.messages))
# and the most liked status is...
mymessages[which.max(mylikes)]
myposts[0]
myposts[1]
myposts[[0]]
myposts[[1]]
print(head(myposts[[0]]))
print(head(myposts[[0]],2))
print(myposts[[0]])
myposts[[0]]
print(myposts[0])
print(head(myposts[0],2))
### TED FACEBOOK PAGE
# http://www.facebook.com/TED
# TED's Facebook ID 29092950651 can be found on http://graph.facebook.com/TED
ted <- list()
i<-0
next.path <- "29092950651/posts"
# download all TED posts
while(length(next.path)!=0) {
i<-i+1
ted[[i]] <- facebook( path=next.path , access_token=access_token)
next.path <- sub("https://graph.facebook.com/","",ted[[i]]$paging$'next')
}
ted[[i]] <- NULL
# parse just video links posted by TED
parse.count.ted <- function(x)
if (x$type=="link" & x$from$id=="29092950651") x$likes$count else NA
parse.link.ted <- function(x)
if (x$type=="link" & x$from$id=="29092950651") x$link else NA
ted.counts <- unlist(sapply(ted, parse.master, f=parse.count.ted))
ted.links <- unlist(sapply(ted, parse.master, f=parse.link.ted))
# see three most popular talks
ted.links[order(ted.counts,decreasing=TRUE)][1:3]
# go to 'https://developers.facebook.com/tools/explorer' to get your access token
access_token <- "AAACEdEose0cBAI3tAm30KPPQdapGLQ9Mx3nd15rgVUH3kt97uPWd5qpffR2ZCKaO2M4oQP3RkxgT48xZB9LFMhKbZAZA2r5HrHCLDZC8vhQZDZD"
require(RCurl)
require(rjson)
options(RCurlOptions = list(capath = system.file("CurlSSL", "cacert.pem", package = "RCurl"), ssl.verifypeer = FALSE))
# Facebook json function copied from original (Romain Francois) post
facebook <-  function( path = "me", access_token, options){
if( !missing(options) ){
options <- sprintf( "?%s", paste( names(options), "=", unlist(options), collapse = "&", sep = "" ) )
} else {
options <- ""
}
data <- getURL( sprintf( "https://graph.facebook.com/%s%s&access_token=%s", path, options, access_token ) )
fromJSON( data )
}
### MY FACEBOOK POSTS
myposts <- list()
i <- 0
next.path <- "me/posts"
# download all my posts
while(length(next.path)!=0) {
i<-i+1
myposts[[i]] <- facebook(path=next.path , access_token=access_token)
next.path <- sub("https://graph.facebook.com/", "", myposts[[i]]$paging$'next')
}
myposts[[i]] <- NULL
# parse the list, extract number of likes and the corresponding text (status)
parse.master <- function(x, f)
sapply(x$data, f)
parse.likes <- function(x) if(!is.null(x$likes$count)) x$likes$count else 0
mylikes <- unlist(sapply(myposts, parse.master, f=parse.likes))
parse.messages <- function(x) if(!is.null(x$message)) x$message else NA
mymessages <- unlist(sapply(myposts, parse.master, f=parse.messages))
# and the most liked status is...
mymessages[which.max(mylikes)]
print(parse.messages)
print(mymessage)
print(mymessages)
print(mymessage[which.max(mylikes)]
)
print(mymessages[which.max(mylikes)]
)
print(mymessages[which.max(mylikes)])
# the code uses 'facebook' function from the previous gist (https://gist.github.com/1634662) or
# see the original http://romainfrancois.blog.free.fr/index.php?post/2012/01/15/Crawling-facebook-with-R
# scrape the list of friends
friends <- facebook( path="me/friends" , access_token=access_token)
# extract Facebook IDs
friends.id <- sapply(friends$data, function(x) x$id)
# extract names
friends.name <- sapply(friends$data, function(x)  iconv(x$name,"UTF-8","ASCII//TRANSLIT"))
# short names to initials
initials <- function(x) paste(substr(x,1,1), collapse="")
friends.initial <- sapply(strsplit(friends.name," "), initials)
# friendship relation matrix
N <- length(friends.id)
friendship.matrix <- matrix(0,N,N)
for (i in 1:N) {
tmp <- facebook( path=paste("me/mutualfriends", friends.id[i], sep="/") , access_token=access_token)
mutualfriends <- sapply(tmp$data, function(x) x$id)
friendship.matrix[i,friends.id %in% mutualfriends] <- 1
}
require(Rgraphviz)
# convert relation matrix to graph
g <- new("graphAM", adjMat=friendship.matrix)
# ellipse graph with initials
pdf(file="facebook1.pdf", width=25, height=25)
attrs <- list(node=list(shape="ellipse", fixedsize=FALSE))
nAttrs <- list(label=friends.initial)
names(nAttrs$label) <- nodes(g)
plot(g, "neato", attrs=attrs, nodeAttrs=nAttrs)
dev.off()
# go to 'https://developers.facebook.com/tools/explorer' to get your access token
access_token <- "AAACEdEose0cBAHM6tLxC9etYe4rNkMTSEM2T5ENRbgde7VddIAH23FP5jmJMiWpmI6kfJYXNF3yuoTHhdVKVu8BFrGcUESswXTa7pwZDZD"
require(RCurl)
require(rjson)
options(RCurlOptions = list(capath = system.file("CurlSSL", "cacert.pem", package = "RCurl"), ssl.verifypeer = FALSE))
# Facebook json function copied from original (Romain Francois) post
facebook <-  function( path = "me", access_token, options){
if( !missing(options) ){
options <- sprintf( "?%s", paste( names(options), "=", unlist(options), collapse = "&", sep = "" ) )
} else {
options <- ""
}
data <- getURL( sprintf( "https://graph.facebook.com/%s%s&access_token=%s", path, options, access_token ) )
fromJSON( data )
}
### MY FACEBOOK POSTS
myposts <- list()
i <- 0
next.path <- "me/posts"
# download all my posts
while(length(next.path)!=0) {
i<-i+1
myposts[[i]] <- facebook(path=next.path , access_token=access_token)
next.path <- sub("https://graph.facebook.com/", "", myposts[[i]]$paging$'next')
}
myposts[[i]] <- NULL
# parse the list, extract number of likes and the corresponding text (status)
parse.master <- function(x, f)
sapply(x$data, f)
parse.likes <- function(x) if(!is.null(x$likes$count)) x$likes$count else 0
mylikes <- unlist(sapply(myposts, parse.master, f=parse.likes))
parse.messages <- function(x) if(!is.null(x$message)) x$message else NA
mymessages <- unlist(sapply(myposts, parse.master, f=parse.messages))
# and the most liked status is...
mymessages[which.max(mylikes)]
# the code uses 'facebook' function from the previous gist (https://gist.github.com/1634662) or
# see the original http://romainfrancois.blog.free.fr/index.php?post/2012/01/15/Crawling-facebook-with-R
# scrape the list of friends
friends <- facebook( path="me/friends" , access_token=access_token)
# extract Facebook IDs
friends.id <- sapply(friends$data, function(x) x$id)
# extract names
friends.name <- sapply(friends$data, function(x)  iconv(x$name,"UTF-8","ASCII//TRANSLIT"))
# short names to initials
initials <- function(x) paste(substr(x,1,1), collapse="")
friends.initial <- sapply(strsplit(friends.name," "), initials)
# friendship relation matrix
N <- length(friends.id)
friendship.matrix <- matrix(0,N,N)
for (i in 1:N) {
tmp <- facebook( path=paste("me/mutualfriends", friends.id[i], sep="/") , access_token=access_token)
mutualfriends <- sapply(tmp$data, function(x) x$id)
friendship.matrix[i,friends.id %in% mutualfriends] <- 1
}
require(Rgraphviz)
# convert relation matrix to graph
g <- new("graphAM", adjMat=friendship.matrix)
# ellipse graph with initials
pdf(file="facebook1.pdf", width=25, height=25)
attrs <- list(node=list(shape="ellipse", fixedsize=FALSE))
nAttrs <- list(label=friends.initial)
names(nAttrs$label) <- nodes(g)
plot(g, "neato", attrs=attrs, nodeAttrs=nAttrs)
dev.off()
require(pixmap)
# download small profile picture of each friend
dir.create("photos")
for (i in 1:length(friends.id))
download.file(paste("http://graph.facebook.com", friends.id[i], "picture", sep="/"),
destfile=paste("photos/",friends.id[i],".jpg",sep=""))
system('for i in `ls photos/*.jpg`; do j=${i%.*}; convert $j.jpg $j.pnm; done', wait=TRUE)
# customized node plotting function
makeNodeDrawFunction <- function(x) {
force(x)
function(node, ur, attrs, radConv) {
photo <- read.pnm(paste("photos/", x, ".pnm", sep=""))
nc <- getNodeCenter(node)
addlogo(photo, c(getX(nc)-25, getX(nc)+25), c(getY(nc)-25, getY(nc)+25))
}
}
drawFuns <- apply(as.array(friends.id), 1, makeNodeDrawFunction)
# a graph with photos
pdf(file="facebook2.pdf", width=25, height=25)
attrs <- list(node=list(shape="box", width=0.75, height=0.75))
plot(g, "neato", attrs=attrs, drawNode=drawFuns)
dev.off()
lapply
mufunc <- function(x) {x^2}
x <- c(1, 2, 3, 4, 5)
lapply(x, myfunc)
lapply(x, mufunc)
sapply(x, mufunc)
rnorm(1)
rnorm(2)
rnorm(3)
rnorm(4)
rnorm(100)
runif(100)
rpois(100)
rpois(100,1)
x <- rnorm(100)
sapply(x, quantile, probs = c(.25, .75))
x
runif
x <- runif(100)
sapply(x, quantile, probs=c(.25, .75))
x
rnorm
gl
library(lattice)
library(nlme)
xyplot(distance ~ age | Subject, data = Orthodont)
xyplot(distance ~ age | Subject, data = Orthodont, type="b")
?gl
?plotmath
?rf
set.seed(31);
heightsCM = rnorm(30,mean=188, sd=5);
weightsK = rnorm(30,mean=84,sd=3);
hasDaughter = sample(c(TRUE,FALSE),size=30,replace=T);
dataFrame = data.frame(heightsCM,weightsK,hasDaughter);
dataframe[dataframe$heightCM > 188]
dataFrameSubset <- dataFrame[dataFrame$heightCM > 188,]
mean(dataFrameSubset$weightsK)
?subset
dataFrameSubset <- subset(dataFrame,dataFrame$heightCM > 188)
dataFrameSubset <- subset(dataFrame,heightCM > 188)
dataFrameSubset <- dataFrame[heightsCM > 188,]
mean(dataFrameSubset$weightsK)
set.seed(41)
rcauchy
cauchy <- rcauchy(100)
set.seed(415)
sample
sample(cauchy,10, replace=TRUE)
library(tm)
install.packages("tm")
library(tm)
stemDocument("miners mining mines")
install.packages("Snowball")
stemDocument("miners mining mines")
stemDocument("miners mining mines", "english")
quit
exit
library(tm)
library(Snowball)
stemDocument("miners mining mines")
library(tm)
library(Snowball)
stemDocument("miners mines mining", "english")
wekajar="C:\Users\Ed\Documents\R\win-library\2.13\RWekajars\java\weka.jar"
oldcp = Sys.getenv("CLASSPATH")
newcp=NULL
Sys.setenv(CLASSPATH=past(wekajar, newcp, sep=":"))
library(tm)
stemDocument("miners mining mines", language="english")
wekajar="C:\Users\Ed\Documents\R\win-library\2.13\RWekajars\java\weka.jar"
wekajar="C:\\Users\\Ed\\Documents\\R\\win-library\\2.13\\RWekajars\\java\\weka.jar"
oldcp = Sys.getenv("CLASSPATH")
oldcp
newcp = NULL
Sys.setenv(CLASSPATH=paste(wekajar, newcp, sep=":"))
library(tm)
stemDocument("mining miners mines", language="english")
newcp2 = c(newcp, ",", oldcp)
newcp2
find.java <- function() {
for (root in c("HLM", "HCU")) for (key in c("Software\\JavaSoft\\Java Runtime Environment",
"Software\\JavaSoft\\Java Development Kit")) {
hive <- try(utils::readRegistry(key, root, 2),
silent = TRUE)
if (!inherits(hive, "try-error"))
return(hive)
}
hive
}
source('~/.active-rstudio-document', echo=TRUE)
find.java()
R.version
library(tm)
library(Snowball)
stemDocument("miners mining mines", "english")
library(rJava)
stemDocument("miners mining mines", "english")
library(tm)
library(Snowball)
library(rJava)
stemDocument("miners mining mines", "english")
stemDocument("miners mining mines", language = "english")
source('~/.active-rstudio-document', echo=TRUE)
find.java()
wekajar = "C:\Users\Ed\Documents\R\win-library\2.13\RWekajars\java\weka.jar"
wekajar = "C:\\Users\\Ed\\Documents\\R\\win-library\\2.13\\RWekajars\\java\\weka.jar"
oldcp = Sys.getenv("CLASSPATH")
OLDCP
oldcp
newcp = NULL
sys.setenv(CLASSPATH=paste(wekajar, newcp, sep=":"))
Sys.setenv(CLASSPATH=paste(wekajar, newcp, sep=":"))
library("tm")
library("Snowball")
stemDocument("miners mining mines", "english")
Sys.setenv(CLASSPATH=paste(wekajar, newcp, oldcp, sep=":"))
library("tm")
library("Snowball")
stemDocument("miners mining mines", "english")
source("http://bioconductor.org/biocLite.R")
source("http://bioconductor.org/biocLite.R")
rm(biocLite)
source("http://bioconductor.org/biocLite.R")
biocLite()
library(datasets)
dat(iris)
data(iris)
?iris
summary(iris)
?cut
apply(iris, cut(x, breaks=x$Species), mean)
apply(iris, cut(iris, breaks=iris$Species), mean)
apply(iris, cut(iris$Sepal.Length, breaks=iris$Species), mean)
apply(iris, cut(iris$Sepal.Length, breaks="iris$Species="virginica""), mean)
apply(iris, cut(iris$Sepal.Length, breaks="iris$Species="virginica"), mean)
apply(iris, cut(iris$Sepal.Length, breaks="virginica"), mean)
apply(iris, cut(iris$Sepal.Length, labels="virginica"), mean)
?split
apply(iris, split(iris, iris$Species), mean)
?split
tapply(iris, iris$Species, mean)
tapply(iris$sepal.length, iris$Species, mean)
tapply(iris$Sepal.Length, iris$Species, mean)
colMeans(iris)
apply(iris[, 1:4], 2, mean)
data(mtcars)
?mtcars
with(mtcars, tapply(mpg, cyl, mean))
tapply(mtcars$cyl, mtcars$mpg, mean)
lapply(mtcars, mean)
split(mtcars, mtcars$cyl)
with(mtcars, tapply(mpg, cyl, mean))
x <- with(mtcars, tapply(mpg, cyl, mean))
abs(x$4 - x$8)
?abs
x$8 - x$4
abs(x[1] - x[3])
?mtcars
x <- with(mtcars, tapply(hp, cyl, mean))
x
abs(x[1] - x[3])
library(nlme)
library(lattice)
xyplot(weight~Time | Diet, Bodyweight)
xyplot(weight~Time | Diet, BodyWeight)
?xyplot
?print.trellis
?trellis.par.set
?par
library(datasets)
data(airquality)
str(airquality)
qplot(Wind, Ozone, data=airquality, facets=.~factor(Month))
library(ggplot2)
qplot(Wind, Ozone, data=airquality, facets=.~factor(Month))
airquality = transform(airquality, Month=factor(Month))
qplot(Wind, Ozone, data=qirquality, facts=.~Month)
qplot(Wind, Ozone, data=airquality, facts=.~Month)
qplot(Wind, Ozone, data=airquality, facets=.~Month)
qplot(votes, rating, data=movies) + geom_smooth()
p <- qplot(votes, rating, data=movies)
print(p)
p + stats_smooth("loess")
setwd("~/Coursera/Reproducible Research/RepData_PeerAssessment1")
activity <- read.table(unz("activity.zip", "activity.csv"))
?unz
activity <- read.csv(unz("activity.zip", "activity.csv"))
summary(activity)
View(activity)
str(activity)
activity$date <- as.date(activity$date)
?as.date
activity$date <- strotime(activity$date, "%Y-%m-%d")
activity$date <- strptime(activity$date, "%Y-%m-%d")
str(activity)
hist(activity$steps)
?hist
main("Histogram of Steps")
qplot(steps, data=activity, geom="histogram")
library(ggplot2)
qplot(steps, data=activity, geom="histogram")
qplot(steps, data=activity, geom="histogram", main="Histogram of Steps")
ddply
?ddply
library(plyr)
?ddply
?aggregate
daily <= aggregate(steps~date, data=activity, fun="sum")
daily <- aggregate(steps~date, data=activity, fun="sum")
str(activity)
activity <- read.csv(unz("activity.zip", "activity.csv"))
daily <- aggregate(steps~date, data=activity, fun="sum")
daily <- aggregate(steps~date, data=activity, FUN="sum")
View(daily)
qplot(steps, data=daily, geom="histogram", main="Histogram of Steps")
qplot(steps, data=daily, geom="histogram", main="Histogram of Steps Per Day")
install.packages("knitr")
qplot(steps, data=daily, geom="histogram", main="Histogram of Steps Per Day")
~~~{r echo=TRUE}
hist(daily$steps, main="Histogram of Steps Per Day")
